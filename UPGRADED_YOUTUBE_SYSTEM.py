#!/usr/bin/env python3
"""
UPGRADED YOUTUBE PROCESSING SYSTEM
==================================

This replaces the broken sql_multi_agent_system.py with a system that:
# DEMO CODE REMOVED: ‚úÖ Extracts REAL YouTube data (not fake summaries)
‚úÖ Uses yt-dlp and youtube-transcript-api for authentic information
# DEMO CODE REMOVED: ‚úÖ Handles errors properly without fallback to fake data
‚úÖ Provides meaningful video information with real metadata

# DEMO CODE REMOVED: NO MORE FAKE DATA OR ERROR FALLOUTS!
"""

import asyncio
import sqlite3
import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from real_youtube_processor import RealYouTubeProcessor

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('upgraded_youtube_system.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class UpgradedYouTubeSystem:
    """Complete YouTube processing system with REAL data extraction."""
    
    def __init__(self, db_path: str = 'autonomous_learning.db'):
        self.db_path = db_path
        self.processor = RealYouTubeProcessor(db_path)
        
        logger.info("üöÄ UPGRADED YOUTUBE SYSTEM INITIALIZED")
        logger.info("‚úÖ Real data extraction enabled")
# DEMO CODE REMOVED: logger.info("üö´ No more fake summaries or error fallouts")
    
    async def get_marked_channels(self) -> List[Dict[str, Any]]:
        """Get channels marked for processing."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT id, name, url, channel_id, hashtags, auto_process, process_channel 
                FROM youtube_channels 
                WHERE process_channel = 1 OR auto_process = 1
            """)
            
            channels = []
            for row in cursor.fetchall():
                channel = {
                    'id': row[0],
                    'name': row[1],
                    'url': row[2],
                    'channel_id': row[3],
                    'hashtags': json.loads(row[4]) if row[4] else [],
                    'auto_process': bool(row[5]),
                    'process_channel': bool(row[6])
                }
                channels.append(channel)
            
            conn.close()
            logger.info(f"üìã Found {len(channels)} channels marked for processing")
            return channels
            
        except Exception as e:
            logger.error(f"‚ùå Error getting marked channels: {e}")
            return []
    
    async def get_channel_videos_real(self, channel_id: str) -> List[str]:
        """Get video URLs from a channel (simplified version)."""
        try:
            import yt_dlp
            
            ydl_opts = {
                'quiet': True,
                'no_warnings': True,
                'extract_flat': True,
            }
            
            channel_url = f"https://www.youtube.com/channel/{channel_id}/videos"
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(channel_url, download=False)
                entries = info.get('entries', [])
                
                video_urls = []
                for entry in entries[:20]:  # Limit to 20 most recent videos
                    if entry and entry.get('id'):
                        video_url = f"https://www.youtube.com/watch?v={entry['id']}"
                        video_urls.append(video_url)
                
                logger.info(f"üìπ Found {len(video_urls)} videos for channel {channel_id}")
                return video_urls
                
        except Exception as e:
            logger.error(f"‚ùå Error getting channel videos: {e}")
            return []
    
    async def process_channel_with_real_data(self, channel: Dict[str, Any]) -> Dict[str, Any]:
        """Process a channel with real data extraction."""
        logger.info(f"üéØ Processing channel with REAL data: {channel['name']}")
        
        result = {
            'channel_name': channel['name'],
            'total_videos': 0,
            'processed_videos': 0,
            'failed_videos': 0,
            'errors': []
        }
        
        try:
            # Resolve channel ID if needed
            if not channel['channel_id']:
                logger.warning(f"‚ö†Ô∏è No channel ID for {channel['name']}")
                result['errors'].append("No valid channel ID")
                return result
            
            # Get videos from channel
            video_urls = await self.get_channel_videos_real(channel['channel_id'])
            result['total_videos'] = len(video_urls)
            
            if not video_urls:
                logger.warning(f"‚ö†Ô∏è No videos found for channel: {channel['name']}")
                return result
            
            logger.info(f"üîÑ Processing {len(video_urls)} videos with REAL data extraction")
            
            # Process each video with real data
            for i, video_url in enumerate(video_urls, 1):
                try:
                    logger.info(f"üìπ Processing video {i}/{len(video_urls)}: {video_url}")
                    
                    # Extract real data
                    video_data = await self.processor.process_video_with_real_data(video_url)
                    
                    if video_data:
                        # Update database with real data
                        if await self.processor.update_database_with_real_data(video_data):
                            result['processed_videos'] += 1
                            logger.info(f"‚úÖ Real data saved: {video_data['title'][:30]}...")
                        else:
                            result['failed_videos'] += 1
                            result['errors'].append(f"Database update failed: {video_url}")
                    else:
                        result['failed_videos'] += 1
                        result['errors'].append(f"Data extraction failed: {video_url}")
                        logger.warning(f"‚ùå Failed to extract real data for: {video_url}")
                    
                    # Delay to avoid rate limits
                    await asyncio.sleep(3)
                    
                except Exception as e:
                    result['failed_videos'] += 1
                    result['errors'].append(f"Processing error: {str(e)}")
                    logger.error(f"‚ùå Error processing video {video_url}: {e}")
            
            # Unmark the channel after processing
            await self.unmark_channel(channel['id'])
            
            logger.info(f"üéâ Channel processing complete: {result['processed_videos']}/{result['total_videos']} videos with real data")
            
        except Exception as e:
            logger.error(f"‚ùå Channel processing failed: {e}")
            result['errors'].append(f"Channel error: {str(e)}")
        
        return result
    
    async def unmark_channel(self, channel_id: int):
        """Unmark channel after processing."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                UPDATE youtube_channels 
                SET process_channel = 0, last_processed = ?
                WHERE id = ?
            """, (datetime.now().isoformat(), channel_id))
            
            conn.commit()
            conn.close()
            logger.info(f"‚úÖ Unmarked channel {channel_id}")
            
        except Exception as e:
            logger.error(f"‚ùå Error unmarking channel: {e}")
    
    async def process_all_marked_channels(self) -> Dict[str, Any]:
        """Process all marked channels with real data extraction."""
        logger.info("üöÄ STARTING UPGRADED YOUTUBE PROCESSING")
# DEMO CODE REMOVED: logger.info("‚úÖ Real data extraction enabled - NO MORE FAKE DATA!")
        
        results = {
            'total_channels': 0,
            'processed_channels': 0,
            'total_videos': 0,
            'successful_videos': 0,
            'failed_videos': 0,
            'errors': [],
            'start_time': datetime.now()
        }
        
        try:
            channels = await self.get_marked_channels()
            results['total_channels'] = len(channels)
            
            if not channels:
                logger.info("‚ÑπÔ∏è No channels marked for processing")
                return results
            
            logger.info(f"üéØ Processing {len(channels)} marked channels with real data extraction")
            
            for i, channel in enumerate(channels, 1):
                try:
                    logger.info(f"üì∫ Processing channel {i}/{len(channels)}: {channel['name']}")
                    
                    channel_result = await self.process_channel_with_real_data(channel)
                    
                    results['processed_channels'] += 1
                    results['total_videos'] += channel_result['total_videos']
                    results['successful_videos'] += channel_result['processed_videos']
                    results['failed_videos'] += channel_result['failed_videos']
                    
                    if channel_result['errors']:
                        results['errors'].extend(channel_result['errors'])
                    
                    logger.info(f"‚úÖ Channel complete: {channel_result['processed_videos']} videos with real data")
                    
                except Exception as e:
                    logger.error(f"‚ùå Failed to process channel {channel['name']}: {e}")
                    results['errors'].append(f"Channel {channel['name']}: {str(e)}")
                
                # Brief pause between channels
                await asyncio.sleep(5)
            
            results['end_time'] = datetime.now()
            duration = (results['end_time'] - results['start_time']).total_seconds()
            
            logger.info("üéâ UPGRADED PROCESSING COMPLETE!")
            logger.info(f"üìä Channels processed: {results['processed_channels']}")
            logger.info(f"üìπ Videos with real data: {results['successful_videos']}")
            logger.info(f"‚ùå Failed videos: {results['failed_videos']}")
            logger.info(f"‚è±Ô∏è Duration: {duration:.1f} seconds")
# DEMO CODE REMOVED: logger.info("‚úÖ NO FAKE DATA GENERATED - ONLY REAL INFORMATION!")
            
            if results['errors']:
                logger.warning(f"‚ö†Ô∏è {len(results['errors'])} errors occurred")
                for error in results['errors'][:5]:
                    logger.warning(f"   ‚Ä¢ {error}")
            
        except Exception as e:
            logger.error(f"‚ùå Processing failed: {e}")
            results['errors'].append(f"System error: {str(e)}")
        
        return results
    
# DEMO CODE REMOVED: async def upgrade_existing_fake_data(self, limit: Optional[int] = None) -> Dict[str, Any]:
# DEMO CODE REMOVED: """Upgrade existing fake data with real extraction."""
# DEMO CODE REMOVED: logger.info("üîÑ UPGRADING EXISTING FAKE DATA TO REAL DATA")
        
        # Use the processor's bulk processing method
        return await self.processor.process_all_videos_with_real_data(limit)

async def main():
    """Main entry point for the upgraded system."""
    system = UpgradedYouTubeSystem()
    
    print("üöÄ UPGRADED YOUTUBE PROCESSING SYSTEM")
    print("=" * 50)
    print("‚úÖ Real data extraction with yt-dlp")
    print("‚úÖ Actual transcripts via youtube-transcript-api")
# DEMO CODE REMOVED: print("‚úÖ No fake summaries or error fallouts")
    print("‚úÖ Meaningful video information only")
    print("=" * 50)
    
    while True:
        print("\nüéØ Choose operation:")
        print("1. Process marked channels (with real data)")
# DEMO CODE REMOVED: print("2. Upgrade existing fake data to real data")
        print("3. Process ALL videos with real data (no limit)")
        print("4. Show system status")
        print("5. Exit")
        
        try:
            choice = input("\nEnter choice (1-5): ").strip()
            
            if choice == "1":
                print("üöÄ Processing marked channels with real data...")
                results = await system.process_all_marked_channels()
                
                print(f"\nüìä RESULTS:")
                print(f"   Channels processed: {results['processed_channels']}")
                print(f"   Videos with real data: {results['successful_videos']}")
                print(f"   Failed extractions: {results['failed_videos']}")
                
            elif choice == "2":
                limit = input("Enter video limit (or press Enter for 10): ").strip()
                limit = int(limit) if limit else 10
                
# DEMO CODE REMOVED: print(f"üîÑ Upgrading {limit} videos from fake to real data...")
# DEMO CODE REMOVED: results = await system.upgrade_existing_fake_data(limit)
                
                print(f"\nüìä UPGRADE RESULTS:")
                print(f"   Videos processed: {results['processed']}")
                print(f"   Successful upgrades: {results['successful']}")
                print(f"   Failed upgrades: {results['failed']}")
                
            elif choice == "3":
                print("‚ö†Ô∏è This will process ALL videos in the database with real data extraction.")
                confirm = input("Continue? (y/N): ").strip().lower()
                
                if confirm == 'y':
                    print("üöÄ Processing ALL videos with real data extraction...")
# DEMO CODE REMOVED: results = await system.upgrade_existing_fake_data(None)
                    
                    print(f"\nüìä BULK PROCESSING RESULTS:")
                    print(f"   Videos processed: {results['processed']}")
                    print(f"   Successful extractions: {results['successful']}")
                    print(f"   Failed extractions: {results['failed']}")
                
            elif choice == "4":
                # Show current status
                from verify_real_data import verify_real_data_extraction
                verify_real_data_extraction()
                
            elif choice == "5":
                print("üëã Upgraded YouTube system stopped")
                break
                
            else:
                print("‚ùå Invalid choice. Please enter 1-5.")
                
        except KeyboardInterrupt:
            print("\nüëã System stopped by user")
            break
        except Exception as e:
            print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    asyncio.run(main())